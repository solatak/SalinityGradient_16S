---
title: "Infer ASVs with DADA2"
author: "Sola Takahashi"
date: "`r Sys.Date()`"
output: html_document
  toc: yes
  toc_float:
    collapsed: no
    smooth_scroll: yes
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      fig.align = "center",
                      fig.path = "../figures/01_DADA2/") # send any figure output to this folder
```

# Before you start

# Set my seed
```{r set-seed}
# Any number can be chosen
set.seed(061898)
```

# Goals of this file

1. Use raw fastq files and generate quality plots to assess quality of reads.
2. Filter and trim out bad sequences and bases from our sequencing files.
3. Write out fastq files with high quality sequences.
4. Evaluate the quality from out filter and trim. 
5. Infer Erros in forward and reverse reads individually. 
6. infer the ASVs on forward and reverse reads seperately, using the rror model. 
7. Merge forward and reverse ASVs into "contiguous ASVs".
8. Generate the ASV count table. ('otu_table' input for phyloseq.).


Output that we need:

1. ASV Count Table: 'otu_table'
2. Taxonomy Table: 'tax_table'
3. Sample Information: 'sample_data' track the reads lost throughout the DADA2 workflow pipelne 

# Load libraries 
```{r load-libraries}
#install.packages("devtools")
library(devtools)

#devtools::install_github("benjjneb/dada2")
library(dada2)

install.packages("tidyverse")
library(tidyverse)
```



# Load Data
```{r load-data}
# Set the raw fastq path to the raw sequencing files 
# Path to the fastq files 
raw_fastqs_path <- "data/01_DADA2/01_raw_gzipped_fastqs"
raw_fastqs_path

# What files are in this path? Intuition Check
head(list.files(raw_fastqs_path))

# How many files are there?
str(list.files(raw_fastqs_path))
# each spot represents one fastq file 

# because paired end data
# Forward read (R1) 515F
# Reverse read (R2) 806R
# don't have primers in sequences because they have been removed, important to know if primers were included or not
# V3-V4 the overlap would be very short (430 bp). but with just V4 the overlap is majority (2 quality scores) (250 bp), can figure out true error v false error more 


# Create a vector of forward reads
# check how many files we should get
forward_reads <- list.files(raw_fastqs_path, pattern = "R1_001.fastq.gz", full.names = TRUE)

# Intution Check
head(forward_reads)

# Create a vector of reverse reads
reverse_reads <- list.files(raw_fastqs_path, pattern = "R2_001.fastq.gz", full.names = TRUE)
head(reverse_reads)


```

# Raw Quality Plots
```{r raw-quality-plot}
# Randomly select 2 samples from dataset to evaluate
random_samples <- sample(1:length(reverse_reads), size=2)
random_samples
# do 12 for the project

# Calculate and plot the quality of these two samples
plotQualityProfile(forward_reads[random_samples]) + 
  labs(title = "Forward Read Raw Quality")
plotQualityProfile(reverse_reads[random_samples]) +
  labs(title = "Reverse Read Raw Quality")


```

# Prepare a placeholder for fitlered reads
```{r prep-filtered-sequences}
# Vector of our samples; extract the sample info from our files 
samples <- sapply(strsplit(basename(forward_reads), "_"), `[`,1)

# intuition check
head(samples)

# Place filtered reads into filtered_fastqs_path
filtered_fastqs_path <- "data/01_DADA2/02_filtered_fastqs"

# create 2 variables: filtered_F, filtered_R
filtered_forward_reads <- file.path(filtered_fastqs_path, paste0(samples, "_R1_filtered.fastq.gz"))
# intuition check
length(filtered_forward_reads)

filtered_reverse_reads <- file.path(filtered_fastqs_path, paste0(samples, "_R2_filtered.fastq.gz"))
# intuition check
head(filtered_reverse_reads)

```

# Filter and trim Reads

Parameters of filter and trim **DEPEND ON THE DATASET**
(for your project you need to change the factors)
This dataset doesn't have primers, but if you follow the two step Illumina protocol -> the 515F and 806R are included and need to be removed.

- paired end is better than single read data
- 'maxN' = number of N bases, remove all Ns from the data 
- 'maxEE' = quality filtering threshold applied to expected errors, use 1 if possible. Here, if there's 2 expected errors, it's ok. But more than 2, throw away the sequence. Two values, first is for forward reads, second is for reverse. 
- 'trimleft' = remove first three base pairs 
- 'truncQ' = remove anything with quality score lower than

```{r filter-and-trim- quality-plots}
# Assign a vector to filter reads
# Trim out poor bases, first threee bps on F reads
# Write out filtered fastq files
filtered_reads <- 
  filterAndTrim(fwd = forward_reads, filt = filtered_forward_reads,
              rev = reverse_reads, filt.rev = filtered_reverse_reads,
              maxN = 0, maxEE = c(2,2), trimLeft = 3,
              truncQ = 2, rm.phix = TRUE, compress = TRUE) #multithread = TRUE


```


## Trimmed Quality Plots

```{r filterTrim-QC-plots}
plotQualityProfile(filtered_forward_reads[random_samples]) +
  labs(title = "Trimmed Forward Read Quality")

plotQualityProfile(filtered_reverse_reads[random_samples]) +
  labs(title = "Trimmed Reverse Read Quality")
```


# Aggregated Trimmed Files
```{r}
# Aggregate all QC plots
# Install and library patchwork
plotQualityProfile(filtered_forward_reads, aggregate = TRUE) +
  plotQualityProfile(filtered_reverse_reads, aggregate = TRUE) +
```

## Stats on read output from 'filterAndTrim'

```{r filterTrim-stats}
str(filtered_reads)
# output says it is a chr with reads.in and reads.out

# Make output into dataframe
filtered_df <- as.data.frame(filtered_reads)
head(filtered_df)


# Caclulate some stats 
filtered_df %>% 
  reframe(median_reads_in = median(reads.in),
          median_reads_out = medians(reads.out),
          median_percent_retained = (median(reads.out)/(median(reads.in))))
```


# Error Modelling

**NOTE:** Run separately on each illumina dataset.
```{r learn-errors}
# Forward reads
error_forward_reads <- 
  learnErrors(filtered_forward_reads) # multithreaded = TRUE

# Plot forward
plotErrors(error_forward_reads, nominalQ = TRUE) + 
  labs(title = "Forward Read Error Model")

# Reverse reads
error_reverse_reads <-
  learnErrors(filtered_reverse_reads) # multithreaded = TRUE

# Plot reverse
plotErrors(error_reverse_reads, nominalQ = TRUE) + 
  labs(title = "Reverse Read Error Model")
```


# Infer ASVs

Note that this is happening seperately on the forward and reverse reads! This is uniqe to DADA2
```{r infer-ASVs}
# Infer forward ASVs
dada_forward <- dada(filtered_forward_reads,
                     err = error_forward_reads) # multithread = TRUE

# Infer reverse ASVs
dada_reverse <- dada(filtered_reverse_reads,
                     err = error_reverse_reads) # multithread = TRUE

```

# Merge Forward and Reverse ASVs
```{r merge-ASVs}
# merge forward and reverse ASVs
merged_ASVs <- mergePairs(dada_forward,filtered_forward_reads,
                          dada_reverse, filtered_reverse_reads,
                          verbose = TRUE)

# Evaluate the output
typeof(merged_ASVs)
length(merged_ASVs)
names(merged_ASVs)

```


# Generate ASVs Count Table
```{r generate-ASV-table}
# Create the ASV Count Table
raw_ASV_table <- makeSequenceTable(merged_ASVs)

# Write out the file to data/01_DADA2

```





# Session Information
```{r session-info}
# Ensure reproducibility
devtools::session_info()
```


